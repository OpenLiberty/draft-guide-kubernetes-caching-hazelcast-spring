// INSTRUCTION: Please remove all comments that start INSTRUCTION prior to commit. Most comments should be removed, although not the copyright.
// INSTRUCTION: The copyright statement must appear at the top of the file
//
// Copyright (c) 2018 IBM Corporation and others.
// Licensed under Creative Commons Attribution-NoDerivatives
// 4.0 International (CC BY-ND 4.0)
//   https://creativecommons.org/licenses/by-nd/4.0/
//
// Contributors:
//     IBM Corporation
//
:projectid: caching-microservices-hazelcast
:page-layout: guide
:page-duration: 25 minutes
:page-releasedate: 2019-02-15
:page-description: Explore how to use caching in microservices within Kubernetes environment.
:page-tags: ['Hazelcast', 'Caching', 'microservices', 'Kubernetes', 'Containers','Spring Boot' , 'Minikube']
:page-permalink: /guides/{projectid}
:page-related-guides: ['docker', 'kubernetes-intro']
:common-includes: https://raw.githubusercontent.com/OpenLiberty/guides-common/master
:source-highlighter: prettify
:page-seo-title: Caching in microservices with Hazelcast Tutorial
:page-seo-description: How to use Hazelcast with microservices
= Caching Microservices with Hazelcast in Kubernetes

[.hidden]
NOTE: This repository contains the guide documentation source. To view the guide in published form, view it on the https://openliberty.io/guides/{projectid}.html[Open Liberty website].

Use Hazelcast Caching in Open Liberty and Spring Boot based Microservices and deploy to Kubernetes

:minikube-ip: 192.168.99.100
:kube: Kubernetes
:hashtag: #
:win: WINDOWS
:mac: MAC
:linux: LINUX
:hazelcast: Hazelcast


// =================================================================================================
// What you'll learn
// =================================================================================================

== What you'll learn

You will learn how to use Hazelcast distributed caching with Spring Boot, bundle with openliberty and
deploy to a local {kube} cluster.
You will then create a Kubernetes Service which load balance between containers and 
verify that you can share data between Microservices.

The microservice you will deploy is called `hazelcast-caching`. The `hazelcast-caching` microservice simply
helps you put a data and read it back. As Kubernetes Service will send the request to different pod each time 
you initiate the request, the data will be served by shared hazelcast cluster between `hazelcast-caching` pods.
container that it runs in, making it easy to distinguish it from its other replicas. The `ping` microservice

You will use a local single-node {kube} cluster.

== What is {hazelcast}?
Hazelcast is an open source In-Memory Data Grid (IMDG). It provides elastically scalable distributed In-Memory computing, 
widely recognized as the fastest and most scalable approach to application performance.

Hazelcast is designed to scale up to hundreds and thousands of members. 
Simply add new members and they will automatically discover the cluster 
and will linearly increase both memory and processing capacity

=== Why is Spring Boot?
Spring Boot makes it easy to create stand-alone, production-grade Spring based Applications that you can "just run".
To learn more about Spring Boot. 
http://spring.io/projects/spring-boot

// =================================================================================================
// Prerequisites
// =================================================================================================

include::{common-includes}/kube-prereq.adoc[]

// =================================================================================================
// Getting Started
// =================================================================================================

include::{common-includes}/gitclone.adoc[]

// no "try what you'll build" section in this guide since it would be too long due to all setup the user will have to do.


// =================================================================================================
// Staring and preparing your cluster for deployment
// =================================================================================================

include::{common-includes}/kube-start.adoc[]

// =================================================================================================
// Building and containerizing the microservices
// =================================================================================================

== Building and containerizing the microservices

mvn clean install

mention about boost plugin, spring boot with openliberty executable. 

docker images


http://192.168.99.100:31000/put?key=1&value=hazelcast_loves_openliberty
192.168.99.100:31000/get?key=1

explain that data is not shared...



The first step of deploying to {kube} is to build your microservices and containerize them with Docker.

The starting Java project, which you can find in the `start` directory, is a multi-module Maven
project that's made up of the `name` and `ping` microservices. Each microservice resides in its own directory,
`start/name` and `start/ping`. Each of these directories also contains a Dockerfile, which is necessary
for building Docker images. If you're unfamiliar with Dockerfiles, check out the
https://openliberty.io/guides/docker.html[Using Docker containers to develop microservices] guide,
which covers Dockerfiles in depth.

If you're familiar with Maven and Docker, you might be tempted to run a Maven build first and then
use the `.war` file produced by the build to build a Docker image. While it is by no means a wrong
approach, we've setup the projects such that this process is automated
as a part of a single Maven build. This is done by using the `dockerfile-maven` plug-in, which automatically
picks up the Dockerfile located in the same directory as its POM file and builds a Docker image from it.
If you're using Docker for Windows ensure that, on the Docker for Windows _General Setting_ page, the option is set to `Expose daemon on tcp://localhost:2375 without TLS`. This is required by the `dockerfile-maven` part of the build.

Navigate to the `start` directory and run the following command:

```
mvn package
```

The `package` goal automatically invokes the `dockerfile-maven:build` goal, which runs during the
`package` phase. This goal builds a Docker image from the Dockerfile located in the same directory
as the POM file.

During the build, you'll see various Docker messages describing what images are being downloaded and
built. When the build finishes, run the following command to list all local Docker images:

```
docker images
```

Verify that the `name:1.0-SNAPSHOT` and `ping:1.0-SNAPSHOT` images are listed among them, for example:

****
[system]#*{win} | {mac}*#

[source, role="no_copy"]
----
REPOSITORY                                                       TAG
ping                                                             1.0-SNAPSHOT
name                                                             1.0-SNAPSHOT
open-liberty                                                     latest
k8s.gcr.io/kube-proxy-amd64                                      v1.10.3
k8s.gcr.io/kube-scheduler-amd64                                  v1.10.3
k8s.gcr.io/kube-controller-manager-amd64                         v1.10.3
k8s.gcr.io/kube-apiserver-amd64                                  v1.10.3
k8s.gcr.io/etcd-amd64                                            3.1.12
k8s.gcr.io/k8s-dns-dnsmasq-nanny-amd64                           1.14.8
k8s.gcr.io/k8s-dns-sidecar-amd64                                 1.14.8
k8s.gcr.io/k8s-dns-kube-dns-amd64                                1.14.8
k8s.gcr.io/pause-amd64                                           3.1
----

[system]#*{linux}*#

[source, role="no_copy"]
----
REPOSITORY                                                       TAG
ping                                                             1.0-SNAPSHOT
name                                                             1.0-SNAPSHOT
open-liberty                                                     latest
k8s.gcr.io/kube-proxy-amd64                                      v1.10.0
k8s.gcr.io/kube-controller-manager-amd64                         v1.10.0
k8s.gcr.io/kube-apiserver-amd64                                  v1.10.0
k8s.gcr.io/kube-scheduler-amd64                                  v1.10.0
quay.io/kubernetes-ingress-controller/nginx-ingress-controller   0.12.0
k8s.gcr.io/etcd-amd64                                            3.1.12
k8s.gcr.io/kube-addon-manager                                    v8.6
k8s.gcr.io/k8s-dns-dnsmasq-nanny-amd64                           1.14.8
k8s.gcr.io/k8s-dns-sidecar-amd64                                 1.14.8
k8s.gcr.io/k8s-dns-kube-dns-amd64                                1.14.8
k8s.gcr.io/pause-amd64                                           3.1
k8s.gcr.io/kubernetes-dashboard-amd64                            v1.8.1
k8s.gcr.io/kube-addon-manager                                    v6.5
gcr.io/k8s-minikube/storage-provisioner                          v1.8.0
gcr.io/k8s-minikube/storage-provisioner                          v1.8.1
k8s.gcr.io/defaultbackend                                        1.4
k8s.gcr.io/k8s-dns-sidecar-amd64                                 1.14.4
k8s.gcr.io/k8s-dns-kube-dns-amd64                                1.14.4
k8s.gcr.io/k8s-dns-dnsmasq-nanny-amd64                           1.14.4
k8s.gcr.io/etcd-amd64                                            3.0.17
k8s.gcr.io/pause-amd64                                           3.0
----
****

If you don't see the `name:1.0-SNAPSHOT` and `ping:1.0-SNAPSHOT` images, then check the Maven
build log for any potential errors.
In addition, if you are using Minikube, make sure your Docker CLI is configured to use Minikube's Docker daemon and not your host's as described in the previous section.


// =================================================================================================
// Deploying the microservices
// =================================================================================================

== Deploying the microservices

Deploy to kubernetes with explaining kubernetes.yaml
kubectl apply -f kubernetes.yaml





Now that your Docker images are built, deploy them using a Kubernetes resource definition.

A Kubernetes resource definition is a yaml file that contains a description of all your deployments, services, or any other resources that you want to deploy. All resources can also be deleted from the cluster by using the same yaml file that you used to deploy them.

To deploy the `name` and `ping` applications, first create the `kubernetes.yaml` file in the `start` directory:

[source, yaml]
----
include::finish/kubernetes.yaml[tags=**;]
----

This file defines four {kube} resources. It defines two deployments and two services. A {kube} deployment is a resource responsible for controlling the creation and management of pods. A service exposes your deployment so that you can make requests to your containers. Three key items to look at when creating the deployments are the `label`, `image`, and `containerPort` fields. The `label` is a way for a {kube} service to reference specific deployments. The `image` is the name and tag of the docker image that you want to use for this container. Finally, the `containerPort` is the port that your container exposes for purposes of accessing your application. For the services, the key point to understand is that they expose your deployments. The binding between deployments and services is specified by the use of labels -- in this case the `app` label. You will also notice the service has a type of `NodePort`. This means you can access these services from outside of your cluster via a specific port. In this case, the ports will be `31000` and `32000`, but it can also be randomized if the `nodePort` field is not used.

Run the following commands to deploy the resources as defined in kubernetes.yaml:

```
kubectl apply -f kubernetes.yaml
```

When the apps are deployed, run the following command to check the status of your pods:

```
kubectl get pods
```

You'll see an output similar to the following if all the pods are healthy and running:

[source, role="no_copy"]
----
NAME                               READY     STATUS    RESTARTS   AGE
name-deployment-6bd97d9bf6-4ccds   1/1       Running   0          15s
ping-deployment-645767664f-nbtd9   1/1       Running   0          15s
----

You can also inspect individual pods in more detail by running the following command:

```
kubectl describe pods
```

You can also issue the `kubectl get` and `kubectl describe` commands on other {kube} resources, so feel
free to inspect all other resources.

Next you will make requests to your services.

****
[system]#*{win} | {mac}*#

The default hostname for Docker Desktop is `localhost`.

[system]#*{linux}*#

The default hostname for minikube is {minikube-ip}. Otherwise it can be found using the `minikube ip` command.
****

Then `curl` or visit the following URLs to access your microservices, substituting the appropriate hostname:

- {name-api}
- {ping-api}/name-service

The first URL returns a brief greeting followed by the name of the pod that the `name` microservice
runs in. The second URL returns `pong` if it received a good response from the `name-service`
{kube} Service. Visiting `{ping-api}/[kube-service]` in general returns either
a good or a bad response depending on whether `kube-service` is a valid {kube} Service that can be accessed.


== Add Hazelcast and Redeploy microservices

add maven dependencies
do the code change
execute rbac

and show that both pods returning the data

// =================================================================================================
// Scaling with Hazelcast
// =================================================================================================

== Scaling with Hazelcast

Scale the cluster with one more pod and show that you still retrieve the data.

// =================================================================================================
// Testing microservices that are running on {kube}
// =================================================================================================

== Testing microservices that are running on {kube}

Write a simple test similar to THIS
https://github.com/OpenLiberty/guide-kubernetes-intro/blob/master/start/name/src/test/java/it/io/openliberty/guides/name/NameEndpointTest.java


A few tests are included for you to test the basic functionality of the microservices. If a test failure
occurs, then you might have introduced a bug into the code. To run the tests, wait for all pods to be
in the ready state before proceeding further. The default properties defined in the `pom.xml` are:

[cols="15, 100", options="header"]
|===
| *Property*        | *Description*
| cluster.ip        | IP or hostname for your cluster, `{minikube-ip}` by default, which is appropriate when using Minikube.
| name.kube.service | Name of the {kube} Service wrapping the `name` pods, `name-service` by default.
| name.node.port    | The NodePort of the {kube} Service `name-service`, 31000 by default.
| ping.node.port    | The NodePort of the {kube} Service `ping-service`, 32000 by default.
|===

Navigate back to the `start` directory.

****
[system]#*{win} | {mac}*#

Run the integration tests against a cluster running with a hostname of `localhost`:

```
mvn verify -Ddockerfile.skip=true -Dcluster.ip=localhost
```

[system]#*{linux}*#

Run the integration tests against a cluster running at the default Minikube IP address:

```
mvn verify -Ddockerfile.skip=true
```

You can also run the integration tests with an IP address of `192.168.99.100`:

```
mvn verify -Ddockerfile.skip=true -Dcluster.ip=192.168.99.100
```
****

The `dockerfile.skip` parameter is set to `true` in order to skip building a new Docker image.

If the tests pass, you'll see an output similar to the following for each service respectively:

[source, role="no_copy"]
----
-------------------------------------------------------
 T E S T S
-------------------------------------------------------
Running it.io.openliberty.guides.name.NameEndpointTest
Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.673 sec - in it.io.openliberty.guides.name.NameEndpointTest

Results :

Tests run: 1, Failures: 0, Errors: 0, Skipped: 0
----

[source, role="no_copy"]
----
-------------------------------------------------------
 T E S T S
-------------------------------------------------------
Running it.io.openliberty.guides.ping.PingEndpointTest
Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 2.222 sec - in it.io.openliberty.guides.ping.PingEndpointTest

Results :

Tests run: 2, Failures: 0, Errors: 0, Skipped: 0
----


// =================================================================================================
// Tear Down
// =================================================================================================

== Tearing down the environment

When you no longer need your deployed microservices, you can delete all {kube} resources by running the `kubectl delete` command:

```
kubectl delete -f kubernetes.yaml
```


include::{common-includes}/kube-minikube-teardown.adoc[]


// =================================================================================================
// finish
// =================================================================================================

== Great work! You're done!

You have just created a Spring Boot application, bundled it with openliberty and deployed to {kube}. 
You then added {hazelcast} caching to the `hazelcast-caching`  and ran integration tests against `hazelcast-caching` 
that are running in a {kube} cluster.

// Include the below from the guides-common repo to tell users how they can contribute to the guide
include::{common-includes}/finish.adoc[]

// DO NO CREATE ANYMORE SECTIONS AT THIS POINT
// Related guides will be added in automatically here if you included them in ":page-related-guides"
